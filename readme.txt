1. Полагаю, не будет критичным тот факт, что я сохраняю нормализованные данные, а не сгенерированные. Очевидно, что можно перейти к ним, имея mean & sd
2. Почему столько слоев\нейронов? -Ручной перебор показал, что столько сойдет.
3. На мой взгляд было бы логичнее сначала создать и обучить a-e, потом отдельно регрессию, затем собрать воедино модель с одним входом и двумя выходами. Сделано, как требовали.
4. Иной batch_size и validation_split давали большую ошибку.
5. Данные сохраняются округленными просто для того, чтобы визуально можно было сравнить отличия.
6. MSE для декодирования составил 0.00538, MSE для регрессии -- 0.00977. (меня устраивает)